{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses Laptop Camera and Show you in new window\n",
    "source=cv.VideoCapture(0)\n",
    "\n",
    "win_name='camera preview'\n",
    "\n",
    "\n",
    "while cv.waitKey(1)!=27: #The window will not close Until you hit Esc\n",
    "    has_frame,frame=source.read()\n",
    "    if not has_frame:\n",
    "        break\n",
    "    cv.imshow(\"camera preview\",frame)\n",
    "\n",
    "source.release()\n",
    "cv.destroyWindow(\"camera preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Our operations on the frame come here\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv.imshow('frame', frame)\n",
    "    if cv.waitKey(1) == ord('q'):#The window will not close Until you hit q\n",
    "        break\n",
    "#When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "PREVIEW=0\n",
    "BLUR=1\n",
    "FEATURES=2\n",
    "CANNY=3\n",
    "feature_params=dict(maxCorners=500,qualityLevel=0.2,minDistance=15,blockSize=9)\n",
    "[1]\n",
    "image_filter=PREVIEW\n",
    "alive=True\n",
    "source=cv.VideoCapture(0)\n",
    "win_name=\"window\"\n",
    "\n",
    "while alive:\n",
    "    has_frame,frame=source.read()\n",
    "    if not has_frame:\n",
    "        break\n",
    "    \n",
    "    frame=cv.flip(frame,1)\n",
    "    if image_filter==PREVIEW:\n",
    "        result=frame\n",
    "    elif image_filter==CANNY:\n",
    "        result=cv.Canny(frame,80,150)\n",
    "    elif image_filter==BLUR:\n",
    "        result=cv.blur(frame,(5,5))\n",
    "    elif image_filter==FEATURES:\n",
    "        result=frame\n",
    "        frame_gray=cv.cvtColor(frame,cv.COLOR_BGR2GRAY)\n",
    "        corners=cv.goodFeaturesToTrack(frame_gray,**feature_params)\n",
    "        if corners is not None:\n",
    "            for x,y in np.float32(corners).reshape(-1,2):\n",
    "                cv.circle(result,(int(x),int(y)),10,(0,255,0),1)\n",
    "        \n",
    "    cv.imshow(\"window\",result)\n",
    "    key=cv.waitKey(1)\n",
    "    if key==27 or key==ord('q'): # will quit your window after hitting q\n",
    "        alive=False\n",
    "    elif key==ord('c'): # will go to canny mode (which is nothing but outline of you and surrounding) after hitting c\n",
    "        image_filter=CANNY\n",
    "    elif key==ord('f'): # will capture and show circle around your features using edges of features after hitting f\n",
    "        image_filter=FEATURES\n",
    "    elif key==ord('b'): # will go make your capture blur after hitting b\n",
    "        image_filter=BLUR\n",
    "    elif key==ord('p'): # original format after hitting p\n",
    "        image_filter=PREVIEW\n",
    "        \n",
    "source.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Face detection and extraction used on single image\n",
    "import cv2\n",
    "\n",
    "# Load the cascade\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "# Read the input image\n",
    "img = cv2.imread(\"C:/Users/DELL/Downloads/IMG-20190508-WA0002.jpg\")\n",
    "# Convert into grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)#colorc onversion is required\n",
    "# Detect faces\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3,7 ) # features can be changed if its not detecting face or detecting non facial parts as face\n",
    "# Draw rectangle around the faces\n",
    "for (x, y, w, h) in faces:\n",
    "    c=cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2) # cv.rectangle(image,(x,y) coordinates of top left and bottom right corners of rectangle(both necessary),color in(r,g,b),thickness)\n",
    "    cropedimage=img[y:y+h,x:x+w] # creates cropped image\n",
    "    cv2.imwrite('C:/Users/DELL/faces/'+str(w) + str(h) + '_faces.jpg',cropedimage) # save imaage in your desired location\n",
    "    \n",
    "# Display the output\n",
    "width=500\n",
    "height=500\n",
    "dim=(width,height)\n",
    "img=cv2.resize(img,dim,interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detection and extraction from folder containing multiple images\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml') # for face detection\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_eye.xml') # for eye detection\n",
    "def detect(gray, frame) :\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5) \n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        cv2.imwrite(\"C:/Users/DELL/Desktop/faces/\"+str(w)+str(h)+\"sddcv2.jpg\", roi_color) # location to save cropped images\n",
    "        \n",
    "    return frame\n",
    "\n",
    "image_files=glob.glob(\"C:/Users/DELL/Desktop/phone/Telegram Images/*\") #location to read files\n",
    "for images in image_files:\n",
    "    frame = cv2.imread(images)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    canvas = detect(gray, frame)\n",
    "\n",
    "cv2.destroyAllWindows() # Close the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face Detection And extraction used on folder containing multiple folders of multiple images having and not having faces\n",
    "import cv2\n",
    "import numpy\n",
    "import glob\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "def detect(gray, frame) :\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.imwrite(\"C:/Users/DELL/faces/\"+str(w)+str(h)+\"cv2.jpg\", roi_color)#folder path for saving images\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return frame\n",
    "\n",
    "# for importing multiple images from multiple folders\n",
    "folders = glob.glob('C:/Users/DELL/Downloads/lfw-funneled/lfw_funneled/*')#folder path for folder containing folders\n",
    "imagenames_list = []\n",
    "for folder in folders:\n",
    "    for f in glob.glob(folder+'/*.jpg'):\n",
    "        imagenames_list.append(f)\n",
    "\n",
    "        \n",
    "for image in imagenames_list:\n",
    "    frame=cv2.imread(image)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    canvas = detect(gray, frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for continuous capture of images from webcam and detecting(+extraction) of faces\n",
    "import cv2\n",
    "face_cascade=cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "capture=cv2.VideoCapture(0)\n",
    "alive=True\n",
    "No=0\n",
    "Capture=No\n",
    "while alive:\n",
    "    ret,frame=capture.read()\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray,1.3,5)\n",
    "    for x,y,w,h in faces:\n",
    "        frame=cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "        \n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        cv2.imwrite(\"C:/Users/DELL/faces/\"+str(w)+str(h)+\"cv2.jpg\", roi_color)\n",
    "    cv2.imshow('Color',frame)\n",
    "    if cv2.waitKey(1)==ord('q'):\n",
    "        break\n",
    "    \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for capture of images from webcam and detecting(+extraction) of faces if pressed a spacific key\n",
    "\n",
    "import cv2\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "face_cascade=cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "cv2.namedWindow(\"test\")\n",
    "\n",
    "img_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print(\"failed to grab frame\")\n",
    "        break\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray,1.3,5)\n",
    "    for x,y,w,h in faces:\n",
    "        frame=cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "        \n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "    cv2.imshow(\"test\", frame)\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "        # SPACE pressed\n",
    "        img_name = \"opencv_frame_{}.png\".format(img_counter)\n",
    "        cv2.imwrite(\"C:/Users/DELL/faces/\"+str(w)+str(h)+\"cv2.jpg\", roi_color)#location for save\n",
    "        print(\"{} written!\".format(img_name))\n",
    "        img_counter += 1\n",
    "\n",
    "cam.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
